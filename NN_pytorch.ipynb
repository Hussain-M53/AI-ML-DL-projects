{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyME3g1ZuSQt5n6RkgNHMgEq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 1**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###Fully Connected Neural Neural using Pytorch"
      ],
      "metadata": {
        "id": "KaYgid_NRKBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model"
      ],
      "metadata": {
        "id": "GLP3uT_OnKa4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aaQ38lLTNpXy"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "\n",
        "# Define the neural network architecture\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self,nonlin):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Fully connected layer 1\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Fully connected layer 2\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)  # Fully connected layer 3\n",
        "\n",
        "        if nonlin == 'relu':\n",
        "            self.nonlin = nn.ReLU()\n",
        "        elif nonlin == 'sigmoid':\n",
        "            self.nonlin = nn.Sigmoid()\n",
        "        elif nonlin == 'tanh':\n",
        "            self.nonlin = nn.Tanh()\n",
        "        elif nonlin == 'swish':\n",
        "            self.nonlin = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.nonlin(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.nonlin(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Model Fitting/Training with Train Dataset"
      ],
      "metadata": {
        "id": "7xZP4v7xQdPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(net,learning_rate):\n",
        "  optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "  for epoch in range(num_epochs):\n",
        "      running_loss = 0.0\n",
        "      running_acc = 0.0\n",
        "      for _, data in enumerate(train_loader, 0):\n",
        "          X, y = data\n",
        "          optimizer.zero_grad()\n",
        "          outputs = net(X.view(-1, input_size))\n",
        "          loss = ce_loss(outputs, y)\n",
        "          loss.backward()\n",
        "          optimizer.step() \n",
        "          running_loss += loss.item() * X.size(0)\n",
        "          pred = outputs.argmax(dim=1, keepdim=True)\n",
        "          running_acc += pred.eq(y.view_as(pred)).sum().item() \n",
        "      print (f' Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader.dataset):.4f}, acc: {running_acc/len(train_loader.dataset):.4f}')\n"
      ],
      "metadata": {
        "id": "1QHPddCvQaYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prediction"
      ],
      "metadata": {
        "id": "ZBsqNbFaSWBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the network on the test set\n",
        "def predict(net):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "      for data in test_loader:\n",
        "          X, y = data\n",
        "          outputs = net(X.view(-1, input_size))\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += y.size(0)\n",
        "          correct += (predicted == y).sum().item()\n",
        "\n",
        "  print(' Accuracy on the test dataset: %d %%' % (100 * correct / total))\n"
      ],
      "metadata": {
        "id": "XJYGTsl1Ooic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initializing dataset"
      ],
      "metadata": {
        "id": "eThbanJCQvsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "# Define the input size, hidden size, and output size\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "learning_rate= 0.01\n",
        "\n",
        "# Load the MNIST dataset\n",
        "\n",
        "# dataset to train model\n",
        "train_dataset = datasets.MNIST('data/', train=True, download=True, transform=transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# spliting the test data and validation data from test dataset\n",
        "test_dataset = datasets.MNIST('data/', train=False, download=True, transform=transforms.ToTensor())\n",
        "# X_val, X_test, y_val, y_test = train_test_split(test_dataset.data, test_dataset.targets, test_size=0.70, random_state=42)\n",
        "\n",
        "# #dataset to evaluate model\n",
        "# test_data = torch.tensor(X_test)\n",
        "# test_targets = torch.tensor(y_test)\n",
        "# test_dataset = torch.utils.data.TensorDataset(test_data, test_targets)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#dataset to tune the hyper-parameters\n",
        "# val_data = torch.tensor(X_val)\n",
        "# val_targets = torch.tensor(y_val)\n",
        "# validation_dataset = torch.utils.data.TensorDataset(val_data, val_targets)\n",
        "validation_dataset = datasets.MNIST('data/', train=True, download=True, transform=transforms.ToTensor())\n",
        "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "train = iter(train_loader)\n",
        "train_data, train_targets = next(train)\n",
        "\n",
        "for i in range(6):\n",
        "    plt.subplot(2,3,i+1)\n",
        "    plt.imshow(train_data[i][0], cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# # network with RELU as activation function\n",
        "# print(\"Using RELU as activation function\")\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# fit(net,learning_rate)\n",
        "# predict(net)\n",
        "\n",
        "# # network with sigmoid as activation function\n",
        "# print(\"Using sigmoid as activation function\")\n",
        "# net = NeuralNetwork(\"sigmoid\")\n",
        "# fit(net,learning_rate)\n",
        "# predict(net)\n",
        "\n",
        "# # network with tanh as activation function\n",
        "# print(\"Using tanh as activation function\")\n",
        "# net = NeuralNetwork(\"tanh\")\n",
        "# fit(net,learning_rate)\n",
        "# predict(net)\n",
        "\n",
        "# # network with swish as activation function\n",
        "# print(\"Using swish as activation function\")\n",
        "# net = NeuralNetwork(\"swish\")\n",
        "# fit(net,learning_rate)\n",
        "# predict(net)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 758
        },
        "id": "D8syfJ9GOmVS",
        "outputId": "fa74a7f1-84b6-490d-f0c4-cc36d2dbdc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 354995997.51it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31752475.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 157476407.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 17787608.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 2**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "###Tuning Using Hyper-parameters on Validation Set"
      ],
      "metadata": {
        "id": "0NSptL4oaYf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_using_scheduler(net,optimizer,num_epochs,scheduler=None):\n",
        "  ce_loss = nn.CrossEntropyLoss()\n",
        "  for epoch in range(num_epochs):\n",
        "      running_loss = 0.0\n",
        "      running_acc =0.0\n",
        "      for _, data in enumerate(validation_loader, 0):\n",
        "          X, y = data\n",
        "          optimizer.zero_grad()\n",
        "          outputs = net(X.view(-1, input_size))\n",
        "          loss = ce_loss(outputs, y)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          running_loss += loss.item() * X.size(0)\n",
        "          pred = outputs.argmax(dim=1, keepdim=True)\n",
        "          running_acc += pred.eq(y.view_as(pred)).sum().item()    \n",
        "      if scheduler:\n",
        "        scheduler.step\n",
        "      print (f' Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader.dataset):.4f}, acc: {running_acc/len(train_loader.dataset):.4f}')\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    lrate = 0.001\n",
        "    if epoch >= 50:\n",
        "        lrate = 0.0005\n",
        "    elif epoch >= 100:\n",
        "        lrate = 0.0003\n",
        "    return lrate\n",
        "\n",
        "\n",
        "\n",
        "## without any scheduler , tweeking learning rate based on epochs\n",
        "\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=lr_schedule(10)) # 50 epochs\n",
        "# train_using_scheduler(net,optimizer,10)\n",
        "# predict(net)\n",
        "\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=lr_schedule(50)) # 80 epochs\n",
        "# train_using_scheduler(net,optimizer,50)\n",
        "# predict(net)\n",
        "\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=lr_schedule(100)) # 100 epochs\n",
        "# train_using_scheduler(net,optimizer,100)\n",
        "# predict(net)\n",
        "\n",
        "\n",
        "## using scheduler with same learning rate for all scheduler\n",
        "learning_rate = 0.1\n",
        "\n",
        "# print(\"Using StepLR scheduler\")\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "# train_using_scheduler(net,optimizer,10,scheduler)\n",
        "# predict(net)\n",
        "\n",
        "# print(\"Using CyclicLR scheduler\")\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "# scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr = 0.0001, max_lr = 1e-3, step_size_up = 4,mode = \"triangular\")\n",
        "# train_using_scheduler(net,optimizer,scheduler)\n",
        "# predict(net)\n",
        "\n",
        "# print(\"Using ExponentialLR scheduler\")\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer,gamma = 0.5)\n",
        "# train_using_scheduler(net,optimizer,scheduler)\n",
        "# predict(net)\n",
        "\n",
        "# print(\"Using CosineAnnealingLR scheduler\")\n",
        "# net = NeuralNetwork(\"relu\")\n",
        "# optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
        "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer,T_max = 32,eta_min = 1e-4)\n",
        "# train_using_scheduler(net,optimizer,scheduler)\n",
        "# predict(net)"
      ],
      "metadata": {
        "id": "1kkgh5RPRJEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 3**\n",
        "\n",
        "---\n",
        "\n",
        "###Gradient Clipping, batch normalisation and L1 and L2 (weight decay) regularization"
      ],
      "metadata": {
        "id": "UgoD8UF1c8uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the batch size and number of epochs\n",
        "batch_size = 64\n",
        "num_epochs = 10\n",
        "# Define the input size, hidden size, and output size\n",
        "input_size = 784 # 28x28\n",
        "hidden_size = 128\n",
        "output_size = 10\n",
        "learning_rate= 0.01\n",
        "weight_decay = 0.001\n",
        "\n",
        "\n",
        "# Define the neural network architecture\n",
        "class RegularizedNeuralNetwork(nn.Module):\n",
        "    def __init__(self,nonlin):\n",
        "        super(RegularizedNeuralNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)  # Fully connected layer 1\n",
        "        self.bn1 = nn.BatchNorm1d(hidden_size) # batch normalization layer 1\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Fully connected layer 2\n",
        "        self.bn2 = nn.BatchNorm1d(hidden_size) # batch normalization layer 2\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)  # Fully connected layer 3\n",
        "\n",
        "        if nonlin == 'relu':\n",
        "            self.nonlin = nn.ReLU()\n",
        "        elif nonlin == 'sigmoid':\n",
        "            self.nonlin = nn.Sigmoid()\n",
        "        elif nonlin == 'tanh':\n",
        "            self.nonlin = nn.Tanh()\n",
        "        elif nonlin == 'swish':\n",
        "            self.nonlin = nn.SiLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.nonlin(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.nonlin(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "def train_regularized(model, optimizer, weight_decay):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    for epoch in range(num_epochs):\n",
        "      train_acc=0\n",
        "      train_loss=0\n",
        "      for _, (X, y) in enumerate(validation_loader,0):\n",
        "          optimizer.zero_grad()\n",
        "          # each output is of in a 64 batch size : 64 * 938 = 60,000 (train dataset size)\n",
        "          outputs = model(X.view(-1, input_size))  \n",
        "          #calculating loss function\n",
        "          loss = ce_loss(outputs, y) \n",
        "          l2_reg = torch.tensor(0.)\n",
        "          for param in model.parameters():\n",
        "              l2_reg += torch.norm(param)\n",
        "          loss += weight_decay * l2_reg      # l2 regularization\n",
        "          # calculate gradient/partial derivative\n",
        "          loss.backward()\n",
        "          # Apply gradient clipping\n",
        "          nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          # update the weights\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item() * X.size(0)\n",
        "          pred = outputs.argmax(dim=1, keepdim=True)\n",
        "          train_acc += pred.eq(y.view_as(pred)).sum().item()\n",
        "      print (f' Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader.dataset):.4f}, acc: {train_acc/len(train_loader.dataset):.4f}')\n",
        "    \n",
        "# Create an instance of the neural network\n",
        "net = RegularizedNeuralNetwork(\"relu\")\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay) # l1 regularization\n",
        "train_regularized(net,optimizer,weight_decay)\n",
        "predict(net)\n"
      ],
      "metadata": {
        "id": "jCdlLAYKc7kp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32393c23-47da-40bc-f573-a0b6fe29ef7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Epoch [1/10], Loss: 0.7388, acc: 0.8198\n",
            " Epoch [2/10], Loss: 0.3069, acc: 0.9305\n",
            " Epoch [3/10], Loss: 0.2355, acc: 0.9479\n",
            " Epoch [4/10], Loss: 0.1982, acc: 0.9580\n",
            " Epoch [5/10], Loss: 0.1738, acc: 0.9646\n",
            " Epoch [6/10], Loss: 0.1571, acc: 0.9686\n",
            " Epoch [7/10], Loss: 0.1454, acc: 0.9710\n",
            " Epoch [8/10], Loss: 0.1340, acc: 0.9746\n",
            " Epoch [9/10], Loss: 0.1248, acc: 0.9770\n",
            " Epoch [10/10], Loss: 0.1178, acc: 0.9791\n",
            " Accuracy on the test dataset: 97 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 4**\n",
        "\n",
        "---\n",
        "\n",
        "###Grid Search"
      ],
      "metadata": {
        "id": "DCw6lJx_dwNu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from skorch import NeuralNetClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "def fit(model, scheduler,optimizer, weight_decay):\n",
        "    ce_loss = nn.CrossEntropyLoss()\n",
        "    for epoch in range(num_epochs):\n",
        "      train_acc=0\n",
        "      train_loss=0\n",
        "      for _, (X, y) in enumerate(validation_loader,0):\n",
        "          optimizer.zero_grad()\n",
        "          # each output is of in a 64 batch size : 64 * 938 = 60,000 (train dataset size)\n",
        "          outputs = model(X.view(-1, input_size))  \n",
        "          #calculating loss function\n",
        "          loss = ce_loss(outputs, y) \n",
        "          l2_reg = torch.tensor(0.)\n",
        "          for param in model.parameters():\n",
        "              l2_reg += torch.norm(param)\n",
        "          loss += weight_decay * l2_reg      # l2 regularization\n",
        "          # calculate gradient/partial derivative\n",
        "          loss.backward()\n",
        "          # Apply gradient clipping\n",
        "          nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "          # update the weights\n",
        "          optimizer.step()\n",
        "          train_loss += loss.item() * X.size(0)\n",
        "          pred = outputs.argmax(dim=1, keepdim=True)\n",
        "          train_acc += pred.eq(y.view_as(pred)).sum().item()\n",
        "      if scheduler:\n",
        "        scheduler.step\n",
        "      print (f' Epoch [{epoch+1}/{num_epochs}], Loss: {train_loss/len(train_loader.dataset):.4f}, acc: {train_acc/len(train_loader.dataset):.4f}')\n",
        "   \n",
        "\n",
        "# Define hyperparameters to search over\n",
        "lr_range = [0.001, 0.01, 0.1]\n",
        "batch_size_range = [32, 64, 128]\n",
        "\n",
        "# Create parameter grid\n",
        "param_grid = {'lr': lr_range,'batch_size': batch_size_range}\n",
        "\n",
        "net = RegularizedNeuralNetwork(\"relu\")\n",
        "ce_loss = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(),lr = 0.01)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "\n",
        "estimator = NeuralNetClassifier(\n",
        "    net,\n",
        "    max_epochs=10,\n",
        "    lr=0.01,\n",
        "    optimizer='sgd',\n",
        "    criterion=torch.nn.CrossEntropyLoss,\n",
        ")\n",
        "\n",
        "# Create GridSearchCV instance\n",
        "grid_search = GridSearchCV(estimator=estimator, param_grid=param_grid, cv=3, verbose=10)\n",
        "grid_search.fit(validation_dataset.data,validation_dataset.targets)\n",
        "print(grid_search.best_params_)\n",
        "print(grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "em_a7AI2dvJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install skorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--BP1-WP8lEf",
        "outputId": "14fdcd41-a4c0-4a40-afca-4a82a73f806a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting skorch\n",
            "  Downloading skorch-0.12.1-py3-none-any.whl (193 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.7/193.7 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (4.65.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from skorch) (1.22.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.9/dist-packages (from skorch) (0.8.10)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.0->skorch) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.22.0->skorch) (1.2.0)\n",
            "Installing collected packages: skorch\n",
            "Successfully installed skorch-0.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 5**\n",
        "\n",
        "---\n",
        "\n",
        "###5-fold cross validation\n",
        "\n"
      ],
      "metadata": {
        "id": "mClIlib5d6Nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# Define number of folds\n",
        "k = 5\n",
        "\n",
        "# Create KFold instance\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Define batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Define number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Loop over folds\n",
        "for fold, (train_indices, test_indices) in enumerate(kf.split(range(len(train_dataset)))):\n",
        "\n",
        "    # Create train and test samplers\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)\n",
        "    test_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=test_sampler)\n",
        "\n",
        "    #Define model, criterion, optimizer, and scheduler\n",
        "    model = NeuralNetwork(\"relu\")\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=0.1)\n",
        "\n",
        "    # Train model\n",
        "    train_using_scheduler(model, optimizer,num_epochs ,scheduler)\n",
        "\n",
        "    # Evaluate model\n",
        "    predict(model)\n",
        "\n",
        "    # Print results\n",
        "    # print(f\"Fold {fold + 1}: Train Acc: {train_accs[-1]:.4f}, Valid Acc: {valid_accs[-1]:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "# Evaluate base model\n",
        "predict(model)\n",
        "\n",
        "# Print results\n",
        "# print(f\"Base Model: Test Acc: {test_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "rQnWEy1id52R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Part 6** \n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "###Saving and Loading Model"
      ],
      "metadata": {
        "id": "gwlz3GEQZjRS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = './cnn.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "loaded_model = NeuralNetwork()\n",
        "loaded_model.load_state_dict(torch.load(PATH)) # it takes the loaded dictionary, not the path file itself\n",
        "loaded_model.to(device)\n",
        "loaded_model.eval()"
      ],
      "metadata": {
        "id": "_37YxBjlXu0y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}